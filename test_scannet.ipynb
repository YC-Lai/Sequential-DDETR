{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.remove('/home/aicenteruav/catkin_ws/devel/lib/python2.7/dist-packages')\n",
    "\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms.functional as F\n",
    "import torch\n",
    "import numpy as np\n",
    "import datasets.utils as utils\n",
    "from datasets.scannetV2 import make_transforms\n",
    "from util.box_ops import box_cxcywh_to_xyxy\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = Path('./data/scannet')\n",
    "assert root.exists(), f'provided ScanNet path {root} does not exist'\n",
    "\n",
    "PATHS = {\n",
    "    \"train\": (root / \"train.txt\", root / \"scannetv2-labels.combined.tsv\"),\n",
    "    \"val\": (root / \"val.txt\", root / \"scannetv2-labels.combined.tsv\")\n",
    "}\n",
    "\n",
    "image_set='train'\n",
    "data_list, tsv_map = PATHS[image_set]\n",
    "with open(data_list, \"r\") as f:\n",
    "    scene_list = f.read().splitlines()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_frames: 6\n",
      "num_sceneData: [1020, 2160, 2056]\n",
      "scene_start_index: [0, 1020, 3180]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sceneId</th>\n",
       "      <th>dataId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1020</th>\n",
       "      <td>1</td>\n",
       "      <td>1030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3180</th>\n",
       "      <td>2</td>\n",
       "      <td>3195</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      sceneId  dataId\n",
       "0           0       5\n",
       "1020        1    1030\n",
       "3180        2    3195"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_data_Id(index, num_frames, num_sceneData):\n",
    "    sum = 0\n",
    "    for i, num_data in enumerate(num_sceneData):\n",
    "        num_data -= num_frames - 1\n",
    "        sum += num_data\n",
    "        if sum > index:\n",
    "            return i, index + (i + 1) * (num_frames - 1)\n",
    "\n",
    "num_frames = 6\n",
    "data_len = 0\n",
    "num_sceneData = []\n",
    "scene_start_index = []\n",
    "for scene in scene_list:\n",
    "    color_images, depth_images, labels, instances, poses, intrinsic = utils.get_filenames_scannet(root, scene)\n",
    "    scene_start_index.append(data_len)\n",
    "    data_len += len(color_images)\n",
    "    num_sceneData.append(len(color_images)) \n",
    "\n",
    "index_len = data_len - (num_frames - 1) * len(num_sceneData)\n",
    "id_dict = {'sceneId': [], 'dataId': []}\n",
    "for index in range(index_len):\n",
    "    sceneId, dataId = get_data_Id(index, num_frames, num_sceneData)\n",
    "    id_dict[\"sceneId\"].append(sceneId)\n",
    "    id_dict[\"dataId\"].append(dataId)\n",
    "\n",
    "df = pd.DataFrame(data=id_dict)\n",
    "print(\"num_frames: {}\".format(num_frames))\n",
    "print(\"num_sceneData: {}\".format(num_sceneData))\n",
    "print(\"scene_start_index: {}\".format(scene_start_index))\n",
    "df.loc[scene_start_index]\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert to 3D coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_3d(xdata, ydata, zdata, color=None, b_min=2, b_max=8, view=(45, 45)):\n",
    "    fig, ax = plt.subplots(subplot_kw={\"projection\": \"3d\"}, dpi=200)\n",
    "    ax.view_init(view[0], view[1])\n",
    "\n",
    "    ax.set_xlim(b_min, b_max)\n",
    "    ax.set_ylim(b_min, b_max)\n",
    "    ax.set_zlim(b_min, b_max)\n",
    "\n",
    "    ax.scatter3D(xdata, ydata, zdata, c=color, cmap='rgb', s=0.1)\n",
    "\n",
    "MAX_INDEX = len(color_images)  # take up to this index of images\n",
    "SKIP = 50  # take one image of every SKIP to speed up the processing\n",
    "SCENE = 2\n",
    "check_coords = False\n",
    "\n",
    "if check_coords:\n",
    "    color_images, depth_images, labels, instances, poses, intrinsic_path = utils.get_filenames_scannet(root, scene_list[SCENE])\n",
    "    coords_list = []\n",
    "    rgb_list = []\n",
    "    for i in range(0, MAX_INDEX, SKIP):\n",
    "        rgb = utils.load_rgb(color_images[i])\n",
    "        rgb = F.normalize(rgb / 255.0, [0.,0.,0.], [1.,1.,1.])\n",
    "        rgb = F.resize(rgb, (480, 640))\n",
    "        _, coordinates = utils.load_depth_coords(poses[i], depth_images[i], intrinsic_path, load_mode=\"coords\")\n",
    "        rgb_list.append(rgb)\n",
    "        coords_list.append(coordinates)\n",
    "    rgbs = torch.flatten(torch.stack(rgb_list, dim=1), start_dim=1)\n",
    "    coords = torch.flatten(torch.stack(coords_list, dim=1), start_dim=1)\n",
    "\n",
    "    print(\"rgbs shape: {}\".format(rgbs.size()))\n",
    "    print(\"coords shape: {}\".format(coords.size()))\n",
    "    plot_3d(coords[0], coords[1], coords[2], color=rgbs.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_masks_bboxes(insts, masks, bboxes):\n",
    "    for i in range(len(insts)):\n",
    "        image = masks[i].numpy().astype('uint8')\n",
    "        bbox = bboxes[i].numpy()\n",
    "        RGB_img = cv2.cvtColor(image, cv2.COLOR_GRAY2RGB) * 255\n",
    "        cv2.rectangle(RGB_img, (bbox[0], bbox[1]), (bbox[2], bbox[3]), (255, 0, 0), 2)\n",
    "        cv2.imshow('My Image', RGB_img)\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "SCENE = 2\n",
    "check_target = False\n",
    "if check_target:\n",
    "    preprocessing_map = utils.get_preprocessing_map(tsv_map)\n",
    "    _, _, label_paths, instance_paths, _, _ = utils.get_filenames_scannet(root, scene_list[SCENE])\n",
    "    label_list = []\n",
    "    for label, instance in zip(label_paths, instance_paths):\n",
    "        target = utils.load_target(label, instance, preprocessing_map)\n",
    "        check_masks_bboxes(target['insts'], target['masks'], target['boxes'])\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check data loader and transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rgb shape: torch.Size([3, 480, 640])\n",
      "depth shape: torch.Size([1, 480, 640])\n",
      "coords shape: torch.Size([3, 480, 640])\n",
      "rgb min: -2.1179039478302, max: 2.640000581741333\n",
      "depth min: 0.0, max: 4.218999862670898\n",
      "coords min: 0.11424517631530762, max: 10.029654502868652\n",
      "torch.Size([13, 480, 640])\n"
     ]
    }
   ],
   "source": [
    "MAX_INDEX = len(color_images)  # take up to this index of images\n",
    "SKIP = 50  # take one image of every SKIP to speed up the processing\n",
    "SCENE = 2\n",
    "load_mode='coords'\n",
    "\n",
    "transform = make_transforms('train')\n",
    "color_images, depth_images, labels, instances, poses, intrinsic_path = utils.get_filenames_scannet(\n",
    "    root, scene_list[SCENE])\n",
    "preprocessing_map = utils.get_preprocessing_map(tsv_map)\n",
    "for rgb, depth, label, instance, pose in zip(color_images, depth_images, labels, instances, poses):\n",
    "    path_set = dict({'rgb': rgb, 'depth': depth, 'pose': pose,\n",
    "                     'label': label, 'instance': instance, 'intrinsic': intrinsic_path})\n",
    "    rgb, depth, coords, target = utils.scannet_loader(path_set, load_mode, preprocessing_map)\n",
    "    rgb, depth, coords, target = transform(rgb, depth, coords, target)\n",
    "    print(\"rgb shape: {}\".format(rgb.shape))\n",
    "    print(\"depth shape: {}\".format(depth.shape))\n",
    "    print(\"coords shape: {}\".format(coords.shape))\n",
    "    print(\"rgb min: {}, max: {}\".format(torch.min(rgb), torch.max(rgb)))\n",
    "    print(\"depth min: {}, max: {}\".format(torch.min(depth), torch.max(depth)))\n",
    "    print(\"coords min: {}, max: {}\".format(torch.min(coords), torch.max(coords)))\n",
    "    bbox = torch.round(box_cxcywh_to_xyxy(target['boxes'] * torch.Tensor([640, 480, 640, 480])))\n",
    "    check_masks_bboxes(target['insts'], target['masks'], bbox)\n",
    "    break \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "08331a6cbc88ba492f670426f60acf0eb71435a78edc30b8c5ce03d35aab8e53"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit ('deformable_detr': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
