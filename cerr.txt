WARNING: You are using pip version 21.3.1; however, version 22.0.4 is available.
You should consider upgrading via the '/opt/python-3.8.10-gpu-cuda-11.1/bin/python3 -m pip install --upgrade pip' command.
+ GPUS=1
+ RUN_COMMAND='./configs/r50_deformable_detr.sh --masks --no_aux_loss --num_workers 8 --num_frames 12'
+ '[' 1 -lt 8 ']'
+ GPUS_PER_NODE=1
+ MASTER_ADDR=127.0.0.1
+ MASTER_PORT=29511
+ NODE_RANK=0
+ let NNODES=GPUS/GPUS_PER_NODE
+ python3 ./tools/launch.py --nnodes 1 --node_rank 0 --master_addr 127.0.0.1 --master_port 29511 --nproc_per_node 1 ./configs/r50_deformable_detr.sh --masks --no_aux_loss --num_workers 8 --num_frames 12
+ EXP_DIR=exps/r50_deformable_detr
+ PY_ARGS='--masks --no_aux_loss --num_workers 8 --num_frames 12'
+ CUDA_LAUNCH_BLOCKING=1
+ python3 -u main.py --output_dir exps/r50_deformable_detr --masks --no_aux_loss --num_workers 8 --num_frames 12
[W ProcessGroupNCCL.cpp:1569] Rank 0 using best-guess GPU 0 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect.Specify device_ids in barrier() to force use of a particular device.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 39.16it/s]
  0%|          | 0/10 [00:00<?, ?it/s] 30%|███       | 3/10 [00:00<00:00, 29.37it/s] 70%|███████   | 7/10 [00:00<00:00, 30.70it/s]100%|██████████| 10/10 [00:00<00:00, 30.31it/s]
/home/b05501024/.local/lib/python3.8/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)
  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)
/home/b05501024/.local/lib/python3.8/site-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /pytorch/aten/src/ATen/native/BinaryOps.cpp:467.)
  return torch.floor_divide(self, other)
